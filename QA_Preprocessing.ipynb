{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from matplotlib import pyplot as plt\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# parse txt file to make pandas dataframe\n",
    "def parse_file(filename):\n",
    "    D = [] # Documents\n",
    "    Q = [] # Queries\n",
    "    C = [] # Candidates\n",
    "    A = [] # Answers\n",
    "    with open(filename, 'r') as f:\n",
    "        curr_Doc = ''\n",
    "        for line in f.readlines():\n",
    "            if len(line.strip()) == 0:\n",
    "                continue\n",
    "            temp = list(filter(None, re.split('[\\n \\t \\s]', line)))\n",
    "            if not temp[0].isdigit():\n",
    "                raise ValueError('Incorrect Input')\n",
    "            if int(temp[0]) != 21:\n",
    "                curr_Doc += ' ' + ' '.join(temp[1:])\n",
    "            else:\n",
    "                D.append(curr_Doc)\n",
    "                curr_Doc = ''\n",
    "                Q.append(' '.join(temp[1:-2]))\n",
    "                A.append(temp[-2])\n",
    "                C.append(temp[-1])\n",
    "    Docs = pd.Series(D, dtype=str, name='Document')\n",
    "    Quers = pd.Series(Q, dtype=str, name='Query')\n",
    "    Cands = pd.Series(C, dtype=str, name='Candidates')\n",
    "    Anss = pd.Series(A, dtype=str, name='Answer')\n",
    "    return pd.concat([Docs, Quers, Cands, Anss], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 29.6 s, sys: 1.07 s, total: 30.7 s\n",
      "Wall time: 34 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# make datasets for Common Nouns queries\n",
    "raw_CN_train = parse_file('data/cbtest_CN_train.txt')\n",
    "raw_CN_valid = parse_file('data/cbtest_CN_valid_2000ex.txt')\n",
    "raw_CN_test = parse_file('data/cbtest_CN_test_2500ex.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document</th>\n",
       "      <th>Query</th>\n",
       "      <th>Candidates</th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>With almost everything else to make them happ...</td>\n",
       "      <td>replied the XXXXX ; for the king 's aunts were...</td>\n",
       "      <td>ancestors|baby|boy|everyone|fairies|mother|por...</td>\n",
       "      <td>queen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>With almost everything else to make them happ...</td>\n",
       "      <td>replied the queen ; for the XXXXX 's aunts wer...</td>\n",
       "      <td>aunts|baby|king|monarch|mother|occasions|princ...</td>\n",
       "      <td>king</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>With almost everything else to make them happ...</td>\n",
       "      <td>replied the queen ; for the king 's XXXXX were...</td>\n",
       "      <td>ancestors|aunts|books|breakfast|cats|children|...</td>\n",
       "      <td>aunts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This vexed the king even more than the queen ...</td>\n",
       "      <td>`` They are very kind old ladies in their way ...</td>\n",
       "      <td>aunts|boots|boy|cat|cats|child|grandmother|kin...</td>\n",
       "      <td>king</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This vexed the king even more than the queen ...</td>\n",
       "      <td>`` They are very kind old ladies in their way ...</td>\n",
       "      <td>aunts|boots|boy|breakfast|cat|foot|lady|mother...</td>\n",
       "      <td>boy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Document  \\\n",
       "0   With almost everything else to make them happ...   \n",
       "1   With almost everything else to make them happ...   \n",
       "2   With almost everything else to make them happ...   \n",
       "3   This vexed the king even more than the queen ...   \n",
       "4   This vexed the king even more than the queen ...   \n",
       "\n",
       "                                               Query  \\\n",
       "0  replied the XXXXX ; for the king 's aunts were...   \n",
       "1  replied the queen ; for the XXXXX 's aunts wer...   \n",
       "2  replied the queen ; for the king 's XXXXX were...   \n",
       "3  `` They are very kind old ladies in their way ...   \n",
       "4  `` They are very kind old ladies in their way ...   \n",
       "\n",
       "                                          Candidates Answer  \n",
       "0  ancestors|baby|boy|everyone|fairies|mother|por...  queen  \n",
       "1  aunts|baby|king|monarch|mother|occasions|princ...   king  \n",
       "2  ancestors|aunts|books|breakfast|cats|children|...  aunts  \n",
       "3  aunts|boots|boy|cat|cats|child|grandmother|kin...   king  \n",
       "4  aunts|boots|boy|breakfast|cat|foot|lady|mother...    boy  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_CN_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Now we'll tokenize the sentences into the lists of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "regex = re.compile('[^a-zA-Z , .]')\n",
    "def tokenize_row(row):\n",
    "    modified_row = regex.sub(' ', row)\n",
    "    bag_of_words = list(filter(None, modified_row.lower().split(' ')))\n",
    "    return bag_of_words\n",
    "def tokenize_data(df):\n",
    "    df['Document'] = df['Document'].apply(tokenize_row)\n",
    "    df['Query'] = df['Query'].apply(tokenize_row)\n",
    "    df['Candidates'] = df['Candidates'].apply(lambda row: row.lower().split('|'))\n",
    "    df['Answer'] = df['Answer'].apply(lambda row: row.lower())\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13.4 s, sys: 608 ms, total: 14 s\n",
      "Wall time: 14.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "raw_CN_train = tokenize_data(raw_CN_train)\n",
    "raw_CN_valid = tokenize_data(raw_CN_valid)\n",
    "raw_CN_test = tokenize_data(raw_CN_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document</th>\n",
       "      <th>Query</th>\n",
       "      <th>Candidates</th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[with, almost, everything, else, to, make, the...</td>\n",
       "      <td>[replied, the, xxxxx, for, the, king, s, aunts...</td>\n",
       "      <td>[ancestors, baby, boy, everyone, fairies, moth...</td>\n",
       "      <td>queen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[with, almost, everything, else, to, make, the...</td>\n",
       "      <td>[replied, the, queen, for, the, xxxxx, s, aunt...</td>\n",
       "      <td>[aunts, baby, king, monarch, mother, occasions...</td>\n",
       "      <td>king</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[with, almost, everything, else, to, make, the...</td>\n",
       "      <td>[replied, the, queen, for, the, king, s, xxxxx...</td>\n",
       "      <td>[ancestors, aunts, books, breakfast, cats, chi...</td>\n",
       "      <td>aunts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[this, vexed, the, king, even, more, than, the...</td>\n",
       "      <td>[they, are, very, kind, old, ladies, in, their...</td>\n",
       "      <td>[aunts, boots, boy, cat, cats, child, grandmot...</td>\n",
       "      <td>king</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[this, vexed, the, king, even, more, than, the...</td>\n",
       "      <td>[they, are, very, kind, old, ladies, in, their...</td>\n",
       "      <td>[aunts, boots, boy, breakfast, cat, foot, lady...</td>\n",
       "      <td>boy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Document  \\\n",
       "0  [with, almost, everything, else, to, make, the...   \n",
       "1  [with, almost, everything, else, to, make, the...   \n",
       "2  [with, almost, everything, else, to, make, the...   \n",
       "3  [this, vexed, the, king, even, more, than, the...   \n",
       "4  [this, vexed, the, king, even, more, than, the...   \n",
       "\n",
       "                                               Query  \\\n",
       "0  [replied, the, xxxxx, for, the, king, s, aunts...   \n",
       "1  [replied, the, queen, for, the, xxxxx, s, aunt...   \n",
       "2  [replied, the, queen, for, the, king, s, xxxxx...   \n",
       "3  [they, are, very, kind, old, ladies, in, their...   \n",
       "4  [they, are, very, kind, old, ladies, in, their...   \n",
       "\n",
       "                                          Candidates Answer  \n",
       "0  [ancestors, baby, boy, everyone, fairies, moth...  queen  \n",
       "1  [aunts, baby, king, monarch, mother, occasions...   king  \n",
       "2  [ancestors, aunts, books, breakfast, cats, chi...  aunts  \n",
       "3  [aunts, boots, boy, cat, cats, child, grandmot...   king  \n",
       "4  [aunts, boots, boy, breakfast, cat, foot, lady...    boy  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_CN_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Now let's get some statistics about dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def show_statistics(train_df, valid_df):\n",
    "    print('Number of samples:')\n",
    "    print('\\t Train:', train_df.shape[0])\n",
    "    print('\\t Valid:', valid_df.shape[0])\n",
    "    train_words = train_df['Document'].tolist()\n",
    "    print('Average number of words:')\n",
    "    print('\\t In Documents', \n",
    "          round(sum([len(sublist) for sublist in train_words]) / train_df.shape[0],1))\n",
    "    train_words = train_df['Query'].tolist()\n",
    "    print('\\t In Queries',\n",
    "         round(sum([len(sublist) for sublist in train_words]) / train_df.shape[0],1))\n",
    "    train_words += train_df['Document'].tolist()\n",
    "    train_words += train_df['Candidates'].tolist() + train_df['Answer'].tolist()\n",
    "    # flatten words from different rows\n",
    "    train_words = [item for sublist in train_words for item in sublist]\n",
    "    train_words_freqs = dict(Counter(train_words))\n",
    "    print('Words statistics:')\n",
    "    print('Train:')\n",
    "    print('\\t Total number of words:', len(train_words_freqs))\n",
    "    train_words_freqs = sorted(train_words_freqs.items(), \n",
    "                               key=operator.itemgetter(1),reverse=True)[:10]\n",
    "    print('\\t Ten most frequent words:', train_words_freqs)\n",
    "    \n",
    "    valid_words = valid_df['Document'].tolist() + valid_df['Query'].tolist()\n",
    "    valid_words += valid_df['Candidates'].tolist() + valid_df['Answer'].tolist()\n",
    "    valid_words = [item for sublist in valid_words for item in sublist]\n",
    "    valid_words_freqs = dict(Counter(valid_words))\n",
    "    print('Valid:')\n",
    "    print('\\t Total number of words:', len(valid_words_freqs))\n",
    "    print('\\t Number of new words:', len(set(valid_words) - set(train_words)))\n",
    "    valid_words_freqs = sorted(valid_words_freqs.items(), \n",
    "                               key=operator.itemgetter(1),reverse=True)[:10]\n",
    "    print('\\t Ten most frequent words:', valid_words_freqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples:\n",
      "\t Train: 120769\n",
      "\t Valid: 2000\n",
      "Average number of words:\n",
      "\t In Documents 452.8\n",
      "\t In Queries 29.6\n",
      "Words statistics:\n",
      "Train:\n",
      "\t Total number of words: 42247\n",
      "\t Ten most frequent words: [(',', 3965617), ('the', 3027817), ('.', 2168428), ('and', 2126483), ('to', 1368783), ('a', 1155806), ('of', 1072559), ('he', 935216), ('was', 752051), ('i', 733825)]\n",
      "Valid:\n",
      "\t Total number of words: 8983\n",
      "\t Number of new words: 380\n",
      "\t Ten most frequent words: [(',', 57575), ('the', 52315), ('.', 36092), ('and', 33627), ('to', 24447), ('he', 17570), ('a', 16601), ('of', 15130), ('was', 11801), ('i', 10777)]\n"
     ]
    }
   ],
   "source": [
    "show_statistics(raw_CN_train, raw_CN_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# saves datasets to pdf. \n",
    "# Warning - during extraction, one should use literal_eval from ast for the first three columns.\n",
    "raw_CN_train.to_csv('data/CBT_CN_train.csv',sep=';',index=False)\n",
    "raw_CN_valid.to_csv('data/CBT_CN_valid.csv',sep=';',index=False)\n",
    "raw_CN_test.to_csv('data/CBT_CN_test.csv',sep=';',index=False)\n",
    "del raw_CN_train\n",
    "del raw_CN_valid\n",
    "del raw_CN_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Now we'll do the same steps for other three classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 30.5 s, sys: 3.44 s, total: 34 s\n",
      "Wall time: 3min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# make datasets for Named Entities queries\n",
    "raw_NE_train = parse_file('data/cbtest_NE_train.txt')\n",
    "raw_NE_valid = parse_file('data/cbtest_NE_valid_2000ex.txt')\n",
    "raw_NE_test = parse_file('data/cbtest_NE_test_2500ex.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "raw_NE_train = tokenize_data(raw_NE_train)\n",
    "raw_NE_valid = tokenize_data(raw_NE_valid)\n",
    "raw_NE_test = tokenize_data(raw_NE_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples:\n",
      "\t Train: 108719\n",
      "\t Valid: 2000\n",
      "Average number of words:\n",
      "\t In Documents 417.2\n",
      "\t In Queries 27.1\n",
      "Words statistics:\n",
      "Train:\n",
      "\t Total number of words: 47537\n",
      "\t Ten most frequent words: [(',', 3152050), ('the', 2158358), ('.', 1955513), ('and', 1641299), ('to', 1116485), ('a', 958834), ('of', 867286), ('he', 726103), ('i', 680264), ('was', 622257)]\n",
      "Valid:\n",
      "\t Total number of words: 9321\n",
      "\t Number of new words: 499\n",
      "\t Ten most frequent words: [(',', 50315), ('the', 39156), ('.', 36248), ('and', 27244), ('to', 21299), ('he', 16616), ('a', 14993), ('of', 14726), ('was', 12083), ('i', 10404)]\n"
     ]
    }
   ],
   "source": [
    "show_statistics(raw_NE_train, raw_NE_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# saves datasets to pdf. \n",
    "# Warning - during extraction, one should use literal_eval from ast for the first three columns.\n",
    "raw_NE_train .to_csv('data/CBT_NE_train.csv',sep=';',index=False)\n",
    "raw_NE_valid.to_csv('data/CBT_NE_valid.csv',sep=';',index=False)\n",
    "raw_NE_test.to_csv('data/CBT_NE_test.csv',sep=';',index=False)\n",
    "del raw_NE_train \n",
    "del raw_NE_valid\n",
    "del raw_NE_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 29.8 s, sys: 2.56 s, total: 32.4 s\n",
      "Wall time: 1min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# make datasets for Verbs queries\n",
    "raw_V_train = parse_file('data/cbtest_V_train.txt')\n",
    "raw_V_valid = parse_file('data/cbtest_V_valid_2000ex.txt')\n",
    "raw_V_test = parse_file('data/cbtest_V_test_2500ex.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "raw_V_train = tokenize_data(raw_V_train)\n",
    "raw_V_valid = tokenize_data(raw_V_valid)\n",
    "raw_V_test = tokenize_data(raw_V_test)\n",
    "# saves datasets to pdf. \n",
    "# Warning - during extraction, one should use literal_eval from ast for the first three columns.\n",
    "raw_V_train.to_csv('data/CBT_V_train.csv',sep=';',index=False)\n",
    "raw_V_valid.to_csv('data/CBT_V_valid.csv',sep=';',index=False)\n",
    "raw_V_test.to_csv('data/CBT_V_test.csv',sep=';',index=False)\n",
    "del raw_V_train \n",
    "del raw_V_valid\n",
    "del raw_V_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# make datasets for Prepositions queries\n",
    "raw_P_train = parse_file('data/cbtest_P_train.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw_P_valid = parse_file('data/cbtest_P_valid_2000ex.txt')\n",
    "raw_P_test = parse_file('data/cbtest_P_test_2500ex.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "raw_P_train = tokenize_data(raw_P_train)\n",
    "raw_P_valid = tokenize_data(raw_P_valid)\n",
    "raw_P_test = tokenize_data(raw_P_test)\n",
    "show_statistics(raw_P_train, raw_P_valid)\n",
    "# saves datasets to pdf. \n",
    "# Warning - during extraction, one should use literal_eval from ast for the first three columns.\n",
    "raw_P_train.to_csv('data/CBT_V_train.csv',sep=';',index=False)\n",
    "raw_P_valid.to_csv('data/CBT_V_valid.csv',sep=';',index=False)\n",
    "raw_P_test.to_csv('data/CBT_V_test.csv',sep=';',index=False)\n",
    "del raw_P_train \n",
    "del raw_P_valid\n",
    "del raw_P_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
