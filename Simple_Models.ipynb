{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ast import literal_eval\n",
    "from collections import Counter\n",
    "import itertools\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Let's deal at first with Common Nouns Question Answering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sample_train = pd.read_csv('data/CBT_CN_train.csv',delimiter=';')\n",
    "sample_valid = pd.read_csv('data/CBT_CN_valid.csv',delimiter=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sample_train = sample_train.sample(n=20000, replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sample_train['Document'] = sample_train['Document'].apply(literal_eval)\n",
    "sample_train['Query'] = sample_train['Query'].apply(literal_eval)\n",
    "sample_train['Candidates'] = sample_train['Candidates'].apply(literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document</th>\n",
       "      <th>Query</th>\n",
       "      <th>Candidates</th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>61630</th>\n",
       "      <td>[he, asked, ,, stopping, before, a, window, fu...</td>\n",
       "      <td>[yes, ,, xxxxx, ,, and, jo, felt, as, calm, an...</td>\n",
       "      <td>[miss, block, bundles, dress, grapes, marketin...</td>\n",
       "      <td>sir</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35840</th>\n",
       "      <td>[even, the, fairies, who, had, been, bathing, ...</td>\n",
       "      <td>[the, fairy, opened, her, eyes, slowly, and, l...</td>\n",
       "      <td>[anyone, castle, emperor, flute, middle, palac...</td>\n",
       "      <td>flute</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10415</th>\n",
       "      <td>[the, king, asked, her, who, she, was, ., she,...</td>\n",
       "      <td>[the, procession, was, marching, on, quite, sm...</td>\n",
       "      <td>[contrary, courage, fate, idea, king, man, mot...</td>\n",
       "      <td>king</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111560</th>\n",
       "      <td>[very, beautiful, ,, very, beautiful, indeed, ...</td>\n",
       "      <td>[what, s, the, matter, ,, peter, rabbit, ,, wh...</td>\n",
       "      <td>[sir, clothes, feet, heart, matter, splash, su...</td>\n",
       "      <td>matter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49195</th>\n",
       "      <td>[i, do, n, t, think, any, one, but, you, would...</td>\n",
       "      <td>[all, our, branches, are, famous, in, one, xxx...</td>\n",
       "      <td>[arch, breath, deal, family, muscle, sea, sigh...</td>\n",
       "      <td>way</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Document  \\\n",
       "61630   [he, asked, ,, stopping, before, a, window, fu...   \n",
       "35840   [even, the, fairies, who, had, been, bathing, ...   \n",
       "10415   [the, king, asked, her, who, she, was, ., she,...   \n",
       "111560  [very, beautiful, ,, very, beautiful, indeed, ...   \n",
       "49195   [i, do, n, t, think, any, one, but, you, would...   \n",
       "\n",
       "                                                    Query  \\\n",
       "61630   [yes, ,, xxxxx, ,, and, jo, felt, as, calm, an...   \n",
       "35840   [the, fairy, opened, her, eyes, slowly, and, l...   \n",
       "10415   [the, procession, was, marching, on, quite, sm...   \n",
       "111560  [what, s, the, matter, ,, peter, rabbit, ,, wh...   \n",
       "49195   [all, our, branches, are, famous, in, one, xxx...   \n",
       "\n",
       "                                               Candidates  Answer  \n",
       "61630   [miss, block, bundles, dress, grapes, marketin...     sir  \n",
       "35840   [anyone, castle, emperor, flute, middle, palac...   flute  \n",
       "10415   [contrary, courage, fate, idea, king, man, mot...    king  \n",
       "111560  [sir, clothes, feet, heart, matter, splash, su...  matter  \n",
       "49195   [arch, breath, deal, family, muscle, sea, sigh...     way  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 1. Maximum frequency model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# choose the candidate that has the maximum frequency in Query/Document\n",
    "def maximum_frequency_prediction(row, use_Document_info=False):\n",
    "    temp = row['Query']\n",
    "    if use_Document_info:\n",
    "        temp += row['Document']\n",
    "    freqs = dict(Counter(temp))\n",
    "    ans = row['Candidates'][0]\n",
    "    for w in row['Candidates']:\n",
    "        if w in freqs.keys() and (ans not in freqs.keys() or (freqs[w] > freqs[ans])):\n",
    "            ans = w\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def max_freq_result(df, use_Document_info=False):\n",
    "    accuracy = 0\n",
    "    for _, row in df.iterrows():\n",
    "        if maximum_frequency_prediction(row, use_Document_info) == row['Answer']:\n",
    "            accuracy += 1\n",
    "    print('\\t Accuracy:', round(accuracy / df.shape[0], 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum frequency (corpus):\n",
      "\t Accuracy: 0.13\n",
      "Maximum frequency (corpus + context):\n",
      "\t Accuracy: 0.27\n"
     ]
    }
   ],
   "source": [
    "print('Maximum frequency (corpus):')\n",
    "max_freq_result(sample_train, False)\n",
    "print('Maximum frequency (corpus + context):')\n",
    "max_freq_result(sample_train, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "In the paper \"THE GOLDILOCKS PRINCIPLE: READING CHILDRENâ€™S BOOKS...\" the results are $0.158$ with corpus-only and $0.281$ with corpus+context, which is pretty similar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 2. Embedding model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We simultaneously learn input and output embedding matrices $I, O \\in \\mathbb{R}^{pxd}$, where $p$ is the embedding dimension and $d$ is the dictionary size.\n",
    "\n",
    "\n",
    "For a given input passage $q$ and candidate word $c$ we compute score as:\n",
    "\n",
    "$S(q,w) = (I\\phi(q))^TO\\phi(c)$, where $\\phi(q)$ indicates one-hot representation of $q$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def categorize_row(row, word_to_id):\n",
    "    newrow = []\n",
    "    for word in row:\n",
    "        newrow.append(word_to_id[word])\n",
    "    return np.array(newrow)\n",
    "        \n",
    "def categorize_data(df):\n",
    "    words = list(itertools.chain.from_iterable(df['Document'].values))\n",
    "    words += list(itertools.chain.from_iterable(df['Query'].values))\n",
    "    words += list(itertools.chain.from_iterable(df['Candidates'].values))\n",
    "    words += list(df['Answer'].values)\n",
    "    print('Random word:', words[19374])\n",
    "    words = set(words)\n",
    "    print('Dictionary size:', len(words))\n",
    "    word_to_id = {t: i for i, t in enumerate(words)}\n",
    "    id_to_word = {i: t for i, t in enumerate(words)}\n",
    "    \n",
    "    df['Document'] = df['Document'].apply(lambda row: categorize_row(row, word_to_id))\n",
    "    df['Query'] = df['Query'].apply(lambda row: categorize_row(row, word_to_id))\n",
    "    df['Candidates'] = df['Candidates'].apply(lambda row: categorize_row(row, word_to_id))\n",
    "    df['Answer'] = df['Answer'].apply(lambda word: word_to_id[word])\n",
    "    return len(words), word_to_id, id_to_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1346"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max([len(ar) for ar in sample_train['Query'].values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random word: of\n",
      "Dictionary size: 37714\n"
     ]
    }
   ],
   "source": [
    "dictionary_size, word_to_id, id_to_word = categorize_data(sample_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25107"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_to_id['xxxxx']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2]),)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(sample_train['Query'].iloc[0] == word_to_id['xxxxx'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document</th>\n",
       "      <th>Query</th>\n",
       "      <th>Candidates</th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>61630</th>\n",
       "      <td>[10979, 1873, 6718, 13520, 28857, 2164, 24553,...</td>\n",
       "      <td>[3008, 6718, 25107, 6718, 26010, 21349, 6433, ...</td>\n",
       "      <td>[8752, 1196, 24403, 25492, 17069, 25301, 5153,...</td>\n",
       "      <td>9891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35840</th>\n",
       "      <td>[15562, 1209, 2630, 1810, 35088, 35977, 27719,...</td>\n",
       "      <td>[1209, 26598, 17699, 19163, 33550, 12507, 2601...</td>\n",
       "      <td>[35112, 11611, 1121, 11316, 32622, 11917, 2520...</td>\n",
       "      <td>11316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10415</th>\n",
       "      <td>[1209, 15376, 1873, 19163, 1810, 26044, 19030,...</td>\n",
       "      <td>[1209, 426, 19030, 12360, 22427, 27653, 26037,...</td>\n",
       "      <td>[28373, 13318, 10922, 34622, 15376, 19752, 333...</td>\n",
       "      <td>15376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111560</th>\n",
       "      <td>[31873, 23443, 6718, 31873, 23443, 36951, 6718...</td>\n",
       "      <td>[33817, 27066, 1209, 2734, 6718, 567, 8934, 67...</td>\n",
       "      <td>[9891, 16073, 15128, 4312, 2734, 13996, 21278,...</td>\n",
       "      <td>2734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49195</th>\n",
       "      <td>[17548, 4388, 7229, 19864, 37624, 31786, 33177...</td>\n",
       "      <td>[30029, 35929, 34620, 18148, 453, 13517, 33177...</td>\n",
       "      <td>[2826, 11292, 33679, 23932, 37155, 6425, 1223,...</td>\n",
       "      <td>4797</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Document  \\\n",
       "61630   [10979, 1873, 6718, 13520, 28857, 2164, 24553,...   \n",
       "35840   [15562, 1209, 2630, 1810, 35088, 35977, 27719,...   \n",
       "10415   [1209, 15376, 1873, 19163, 1810, 26044, 19030,...   \n",
       "111560  [31873, 23443, 6718, 31873, 23443, 36951, 6718...   \n",
       "49195   [17548, 4388, 7229, 19864, 37624, 31786, 33177...   \n",
       "\n",
       "                                                    Query  \\\n",
       "61630   [3008, 6718, 25107, 6718, 26010, 21349, 6433, ...   \n",
       "35840   [1209, 26598, 17699, 19163, 33550, 12507, 2601...   \n",
       "10415   [1209, 426, 19030, 12360, 22427, 27653, 26037,...   \n",
       "111560  [33817, 27066, 1209, 2734, 6718, 567, 8934, 67...   \n",
       "49195   [30029, 35929, 34620, 18148, 453, 13517, 33177...   \n",
       "\n",
       "                                               Candidates  Answer  \n",
       "61630   [8752, 1196, 24403, 25492, 17069, 25301, 5153,...    9891  \n",
       "35840   [35112, 11611, 1121, 11316, 32622, 11917, 2520...   11316  \n",
       "10415   [28373, 13318, 10922, 34622, 15376, 19752, 333...   15376  \n",
       "111560  [9891, 16073, 15128, 4312, 2734, 13996, 21278,...    2734  \n",
       "49195   [2826, 11292, 33679, 23932, 37155, 6425, 1223,...    4797  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 1, 0, 0])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(sample_train.iloc[0]['Candidates'] == sample_train.iloc[0]['Answer'],dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample_batch(data, batch_size):\n",
    "    inds = np.random.randint(0, len(data), size=batch_size)\n",
    "    X = []\n",
    "    for arr in data.iloc[inds]['Query'].values:\n",
    "        i = np.where(arr == word_to_id['xxxxx'])[0][0]\n",
    "        arr = list(arr)\n",
    "        d1 = i\n",
    "        d2 = len(arr) - 1 - i\n",
    "        if d1 > 4 and d2 > 4:\n",
    "            X += [arr[i-5:i] + arr[i+1:i+6]]\n",
    "        elif d1 > 4:\n",
    "            X += [arr[i-5:i] + arr[i+1:len(arr)] + [dictionary_size]*(5-d2)]\n",
    "        elif d2 > 4:\n",
    "            X += [[dictionary_size]*(5-d1) + arr[0:i] + arr[i+1:i+6]]\n",
    "    X = np.array(X)\n",
    "    C, y = [], []\n",
    "    for i in inds:\n",
    "        arr = data.iloc[i]['Candidates']\n",
    "        C += [list(arr)]\n",
    "        y += [list(np.array(arr == data.iloc[i]['Answer'],dtype=int))]\n",
    "    C = np.array(C)\n",
    "    y = np.array(y)\n",
    "    return X, C, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_ex, C_ex, y_ex = sample_batch(sample_train, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 10)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_ex.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 30)\n",
      "(?, 10, 30)\n",
      "(?, 10)\n"
     ]
    }
   ],
   "source": [
    "embedding_size = 30\n",
    "tf.reset_default_graph()\n",
    "X = tf.placeholder(tf.int32, [None, 10], name='input_passage')\n",
    "C = tf.placeholder(tf.int32, [None, 10], name='candidates')\n",
    "y = tf.placeholder(tf.int32, [None, 10], name='answers')\n",
    "\n",
    "input_embeddings = tf.Variable(tf.random_uniform([dictionary_size, embedding_size], 0, 0.1, dtype=tf.float32))\n",
    "output_embeddings = tf.Variable(tf.random_uniform([dictionary_size, embedding_size], 0, 0.1, dtype=tf.float32))\n",
    "\n",
    "emb_X = tf.nn.embedding_lookup(input_embeddings, X)\n",
    "emb_X = tf.reduce_sum(emb_X, axis=1)\n",
    "print(emb_X.shape)\n",
    "emb_C = tf.nn.embedding_lookup(output_embeddings, C)\n",
    "print(emb_C.shape)\n",
    "\n",
    "scores = tf.reduce_sum(tf.tensordot(emb_C, emb_X, axes=[2, 1]), axis=2)\n",
    "predictions = tf.nn.softmax(scores)\n",
    "print(predictions.shape)\n",
    "\n",
    "loss = tf.losses.log_loss(labels=y, predictions=predictions)\n",
    "\n",
    "train_op = tf.train.AdamOptimizer().minimize(loss, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s = tf.Session()\n",
    "    \n",
    "s.run(tf.global_variables_initializer())\n",
    "\n",
    "n_epochs = 200\n",
    "batches_per_epoch = 1000\n",
    "batch_size = 10\n",
    "\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "\n",
    "for epoch in tqdm.tqdm(range(n_epochs)):\n",
    "\n",
    "    #print(\"-------\\n\")\n",
    "    old_test_loss = avg_test_loss\n",
    "    avg_test_loss = 0\n",
    "    avg_train_loss = 0\n",
    "    for batch in range(batches_per_epoch):\n",
    "        x_, y_, len_, inds_ = sample_batch(train_ix, raw_data['EAP'], raw_data['HPL'], raw_data['MWS'], batch_size)\n",
    "\n",
    "        _, iloss, y_pred = s.run([train_op, loss, predictions], {X: x_,\n",
    "                                                                y: y_,\n",
    "                                                                lengths: len_,\n",
    "                                                                learning_rate_ph: lr})\n",
    "        avg_train_loss += iloss\n",
    "        x_test, y_test, len_test, _ = sample_batch(test_ix, \n",
    "                                                   raw_data['EAP'], raw_data['HPL'], raw_data['MWS'], batch_size)\n",
    "        \n",
    "        iloss = s.run(loss, {X: x_test,y: y_test, lengths: len_test})\n",
    "        avg_test_loss += iloss\n",
    "\n",
    "    #print(\"EPOCH: \", epoch)\n",
    "    #print(\"AVERAGE TRAIN LOSS: \", avg_train_loss/batches_per_epoch)\n",
    "    #print(\"AVERAGE TEST LOSS: \", avg_test_loss/batches_per_epoch)\n",
    "    train_losses.append([avg_train_loss/batches_per_epoch])\n",
    "    test_losses.append([avg_test_loss/batches_per_epoch])\n",
    "    \n",
    "    if epoch != 0 and avg_test_loss > old_test_loss:\n",
    "        pass\n",
    "        #print('problems...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s = tf.Session()\n",
    "l2 = s.run([one_hotted], {l: sample_train['Document'].iloc[0\n",
    "                                                          ]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37906,)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l2[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0., ...,  0.,  0.,  0.], dtype=float32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l2[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
